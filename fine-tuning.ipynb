{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model, parameters, performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "from models_fine.vqvae import VQVAE\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from torchvision.utils import make_grid\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\"\"\"\n",
    "Utility functions\n",
    "\"\"\"\n",
    "\n",
    "def load_model(model_filename):\n",
    "    path = os.getcwd() + '/results/'\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        data = torch.load(path + model_filename,  weights_only=False)\n",
    "    else:\n",
    "        data = torch.load(path+model_filename,map_location=lambda storage, loc: storage)\n",
    "    \n",
    "    params = data[\"hyperparameters\"]\n",
    "    \n",
    "    model = VQVAE(params['n_hiddens'], params['n_residual_hiddens'],\n",
    "                  params['n_residual_layers'], params['n_embeddings'], \n",
    "                  params['embedding_dim'], params['beta']).to(device)\n",
    "\n",
    "    model.load_state_dict(data['model'])\n",
    "    \n",
    "    return model, data\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "End of utilities\n",
    "\"\"\"\n",
    "\n",
    "model_filename = 'vqvae_data_thu_jun_19_16_39_23_2025.pth'\n",
    "\n",
    "model,vqvae_data = load_model(model_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset and loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "training_data, validation_data, training_loader, validation_loader, x_train_var = utils.load_data_and_data_loaders('CIFAR10', 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 32,\n",
       " 'n_updates': 30000,\n",
       " 'n_hiddens': 128,\n",
       " 'n_residual_hiddens': 32,\n",
       " 'n_residual_layers': 2,\n",
       " 'embedding_dim': 64,\n",
       " 'n_embeddings': 512,\n",
       " 'beta': 0.25,\n",
       " 'learning_rate': 0.0003,\n",
       " 'log_interval': 50,\n",
       " 'dataset': 'CIFAR10',\n",
       " 'save': True,\n",
       " 'filename': 'thu_jun_19_16_39_23_2025'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = vqvae_data['hyperparameters']\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CGA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def update_codebook_with_cga(model, z_e_all, ei_all, ej_all, usage_counts, bottom_percent=0.6):\n",
    "    \"\"\"\n",
    "    Perform genetic algorithm-based update for underutilized codebook tokens.\n",
    "\n",
    "    Parameters:\n",
    "    - model: VQVAE model with .vector_quantization.embedding.weight\n",
    "    - z_e_all: (N, D) encoder outputs flattened\n",
    "    - ei_all: (N,) top-1 encoding indices\n",
    "    - ej_all: (N,) top-2 encoding indices\n",
    "    - usage_counts: (K,) usage count of each codebook vector\n",
    "    - bottom_percent: float, percentage of least-used tokens to consider for update\n",
    "    \"\"\"\n",
    "    device = z_e_all.device\n",
    "    codebook = model.vector_quantization.embedding.weight  # (K, D)\n",
    "    K = codebook.shape[0]\n",
    "\n",
    "    # Identify bottom X% underutilized codeword indices\n",
    "    num_bottom = int(K * bottom_percent)\n",
    "    _, sorted_indices = torch.sort(usage_counts)\n",
    "    underutilized_tokens = sorted_indices[:num_bottom].tolist()\n",
    "\n",
    "    # For collecting e_lo vectors for each underutilized codeword\n",
    "    update_vectors = {k: [] for k in underutilized_tokens}\n",
    "\n",
    "    for z_e, ei, ej in zip(z_e_all, ei_all, ej_all):\n",
    "        if ei.item() not in underutilized_tokens:\n",
    "            continue  # skip if token is not underutilized\n",
    "\n",
    "        e_i = codebook[ei]  # (D,)\n",
    "        e_j = codebook[ej]  # (D,)\n",
    "\n",
    "        # Crossover\n",
    "        alpha = torch.rand(1).item()\n",
    "        e_cross = alpha * e_i + (1 - alpha) * e_j\n",
    "\n",
    "        # Mutation\n",
    "        beta = torch.empty(1).uniform_(-2, 2).item()\n",
    "        e_mut = beta * e_cross\n",
    "\n",
    "        # Local Search\n",
    "        epsilon = torch.randn_like(e_mut)\n",
    "        s = 1.0\n",
    "        e_lo = e_mut + s * epsilon\n",
    "        dist_ei = F.mse_loss(z_e, e_i)\n",
    "        dist_lo = F.mse_loss(z_e, e_lo)\n",
    "\n",
    "        # Find smallest s such that distance condition met\n",
    "        tries = 10\n",
    "        while dist_lo >= dist_ei and tries > 0:\n",
    "            s *= 0.5\n",
    "            e_lo = e_mut + s * epsilon\n",
    "            dist_lo = F.mse_loss(z_e, e_lo)\n",
    "            tries -= 1\n",
    "\n",
    "        update_vectors[ei.item()].append(e_lo)\n",
    "\n",
    "    # Token Update: average e_lo vectors for each token\n",
    "    with torch.no_grad():\n",
    "        for k in underutilized_tokens:\n",
    "            if update_vectors[k]:\n",
    "                update_vectors_tensor = torch.stack(update_vectors[k], dim=0)\n",
    "                model.vector_quantization.embedding.weight[k] = update_vectors_tensor.mean(dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results will be saved in ./results/vqvae_c:\\Users\\minju\\AppData\\Roaming\\jupyter\\runtime\\kernel-v3d251d7a30161ce0661e476edaa1ba3b61613a5c0.json.pth\n",
      "[Epoch 0] Step 0 | Recon: 0.3749 | Loss: 0.4349 | Perplexity: 126.96\n",
      "[Epoch 0] Step 50 | Recon: 0.4133 | Loss: 0.4919 | Perplexity: 130.77\n",
      "[Epoch 0] Step 100 | Recon: 0.3449 | Loss: 0.3903 | Perplexity: 132.32\n",
      "[Epoch 0] Step 150 | Recon: 0.3486 | Loss: 0.3957 | Perplexity: 135.01\n",
      "[Epoch 0] Step 200 | Recon: 0.3378 | Loss: 0.3843 | Perplexity: 128.64\n",
      "[Epoch 0] Step 250 | Recon: 0.3572 | Loss: 0.4067 | Perplexity: 129.96\n",
      "[Epoch 0] Step 300 | Recon: 0.3560 | Loss: 0.4068 | Perplexity: 141.52\n",
      "[Epoch 0] Step 350 | Recon: 0.3494 | Loss: 0.3960 | Perplexity: 129.94\n",
      "[Epoch 0] Step 400 | Recon: 0.3611 | Loss: 0.4026 | Perplexity: 130.17\n",
      "[Epoch 0] Step 450 | Recon: 0.3323 | Loss: 0.3774 | Perplexity: 137.04\n",
      "[Epoch 0] Step 500 | Recon: 0.3432 | Loss: 0.3961 | Perplexity: 139.54\n",
      "[Epoch 0] Step 550 | Recon: 0.3567 | Loss: 0.4060 | Perplexity: 131.95\n",
      "[Epoch 0] Step 600 | Recon: 0.3707 | Loss: 0.4269 | Perplexity: 141.30\n",
      "[Epoch 0] Step 650 | Recon: 0.3511 | Loss: 0.4025 | Perplexity: 133.27\n",
      "[Epoch 0] Step 700 | Recon: 0.3226 | Loss: 0.3697 | Perplexity: 134.32\n",
      "[Epoch 0] Step 750 | Recon: 0.3212 | Loss: 0.3692 | Perplexity: 137.55\n",
      "[Epoch 0] Step 800 | Recon: 0.3503 | Loss: 0.3983 | Perplexity: 133.67\n",
      "[Epoch 0] Step 850 | Recon: 0.3283 | Loss: 0.3789 | Perplexity: 139.16\n",
      "[Epoch 0] Step 900 | Recon: 0.2915 | Loss: 0.3453 | Perplexity: 133.32\n",
      "[Epoch 0] Step 950 | Recon: 0.2839 | Loss: 0.3312 | Perplexity: 132.33\n",
      "[Epoch 0] Step 1000 | Recon: 0.2606 | Loss: 0.3058 | Perplexity: 125.25\n",
      "[Epoch 0] Step 1050 | Recon: 0.3497 | Loss: 0.4082 | Perplexity: 140.22\n",
      "[Epoch 0] Step 1100 | Recon: 0.3255 | Loss: 0.3747 | Perplexity: 143.51\n",
      "[Epoch 0] Step 1150 | Recon: 0.3478 | Loss: 0.4030 | Perplexity: 135.14\n",
      "[Epoch 0] Step 1200 | Recon: 0.3773 | Loss: 0.4419 | Perplexity: 140.41\n",
      "[Epoch 0] Step 1250 | Recon: 0.3609 | Loss: 0.4212 | Perplexity: 136.87\n",
      "[Epoch 0] Step 1300 | Recon: 0.3125 | Loss: 0.3673 | Perplexity: 133.17\n",
      "[Epoch 0] Step 1350 | Recon: 0.3011 | Loss: 0.3571 | Perplexity: 132.51\n",
      "[Epoch 0] Step 1400 | Recon: 0.3156 | Loss: 0.3681 | Perplexity: 137.48\n",
      "[Epoch 0] Step 1450 | Recon: 0.2917 | Loss: 0.3501 | Perplexity: 139.35\n",
      "[Epoch 0] Step 1500 | Recon: 0.3490 | Loss: 0.4248 | Perplexity: 139.51\n",
      "[Epoch 0] Step 1550 | Recon: 0.3299 | Loss: 0.3938 | Perplexity: 143.66\n",
      "[Epoch 0] ⏳ Running CGA update for underutilized tokens...\n",
      "[Epoch 0] ✅ CGA update complete.\n",
      "\n",
      "[Epoch 1] Step 1600 | Recon: 0.3294 | Loss: 0.4101 | Perplexity: 143.24\n",
      "[Epoch 1] Step 1650 | Recon: 0.3181 | Loss: 0.3973 | Perplexity: 139.38\n",
      "[Epoch 1] Step 1700 | Recon: 0.3423 | Loss: 0.4273 | Perplexity: 136.69\n",
      "[Epoch 1] Step 1750 | Recon: 0.2829 | Loss: 0.3645 | Perplexity: 141.19\n",
      "[Epoch 1] Step 1800 | Recon: 0.3115 | Loss: 0.3926 | Perplexity: 150.26\n",
      "[Epoch 1] Step 1850 | Recon: 0.3501 | Loss: 0.4306 | Perplexity: 148.50\n",
      "[Epoch 1] Step 1900 | Recon: 0.2945 | Loss: 0.3797 | Perplexity: 140.69\n",
      "[Epoch 1] Step 1950 | Recon: 0.3428 | Loss: 0.4377 | Perplexity: 146.12\n",
      "[Epoch 1] Step 2000 | Recon: 0.3072 | Loss: 0.4020 | Perplexity: 148.47\n",
      "[Epoch 1] Step 2050 | Recon: 0.2708 | Loss: 0.3554 | Perplexity: 150.90\n",
      "[Epoch 1] Step 2100 | Recon: 0.3254 | Loss: 0.4294 | Perplexity: 144.84\n",
      "[Epoch 1] Step 2150 | Recon: 0.3361 | Loss: 0.4292 | Perplexity: 143.21\n",
      "[Epoch 1] Step 2200 | Recon: 0.2976 | Loss: 0.3906 | Perplexity: 152.10\n",
      "[Epoch 1] Step 2250 | Recon: 0.2960 | Loss: 0.3902 | Perplexity: 149.49\n",
      "[Epoch 1] Step 2300 | Recon: 0.2563 | Loss: 0.3420 | Perplexity: 145.03\n",
      "[Epoch 1] Step 2350 | Recon: 0.3220 | Loss: 0.4254 | Perplexity: 143.71\n",
      "[Epoch 1] Step 2400 | Recon: 0.2730 | Loss: 0.3542 | Perplexity: 142.15\n",
      "[Epoch 1] Step 2450 | Recon: 0.3078 | Loss: 0.4097 | Perplexity: 143.58\n",
      "[Epoch 1] Step 2500 | Recon: 0.3013 | Loss: 0.3983 | Perplexity: 140.06\n",
      "[Epoch 1] Step 2550 | Recon: 0.2814 | Loss: 0.3767 | Perplexity: 151.93\n",
      "[Epoch 1] Step 2600 | Recon: 0.2764 | Loss: 0.3759 | Perplexity: 141.19\n",
      "[Epoch 1] Step 2650 | Recon: 0.2943 | Loss: 0.3783 | Perplexity: 146.77\n",
      "[Epoch 1] Step 2700 | Recon: 0.3123 | Loss: 0.4166 | Perplexity: 149.27\n",
      "[Epoch 1] Step 2750 | Recon: 0.3143 | Loss: 0.4075 | Perplexity: 151.81\n",
      "[Epoch 1] Step 2800 | Recon: 0.2953 | Loss: 0.3949 | Perplexity: 147.12\n",
      "[Epoch 1] Step 2850 | Recon: 0.2840 | Loss: 0.3789 | Perplexity: 150.30\n",
      "[Epoch 1] Step 2900 | Recon: 0.3018 | Loss: 0.4055 | Perplexity: 153.01\n",
      "[Epoch 1] Step 2950 | Recon: 0.3295 | Loss: 0.4402 | Perplexity: 148.31\n",
      "[Epoch 1] Step 3000 | Recon: 0.2947 | Loss: 0.3991 | Perplexity: 145.80\n",
      "[Epoch 1] Step 3050 | Recon: 0.3349 | Loss: 0.4418 | Perplexity: 150.05\n",
      "[Epoch 1] Step 3100 | Recon: 0.2955 | Loss: 0.3864 | Perplexity: 153.67\n",
      "[Epoch 1] ⏳ Running CGA update for underutilized tokens...\n",
      "[Epoch 1] ✅ CGA update complete.\n",
      "\n",
      "[Epoch 2] Step 3150 | Recon: 0.3328 | Loss: 0.4312 | Perplexity: 149.32\n",
      "[Epoch 2] Step 3200 | Recon: 0.2782 | Loss: 0.3826 | Perplexity: 145.39\n",
      "[Epoch 2] Step 3250 | Recon: 0.3359 | Loss: 0.4441 | Perplexity: 143.21\n",
      "[Epoch 2] Step 3300 | Recon: 0.3593 | Loss: 0.4686 | Perplexity: 160.78\n",
      "[Epoch 2] Step 3350 | Recon: 0.3853 | Loss: 0.5122 | Perplexity: 158.67\n",
      "[Epoch 2] Step 3400 | Recon: 0.2611 | Loss: 0.3458 | Perplexity: 150.22\n",
      "[Epoch 2] Step 3450 | Recon: 0.2899 | Loss: 0.3846 | Perplexity: 139.53\n",
      "[Epoch 2] Step 3500 | Recon: 0.3208 | Loss: 0.4267 | Perplexity: 148.03\n",
      "[Epoch 2] Step 3550 | Recon: 0.3107 | Loss: 0.4093 | Perplexity: 158.35\n",
      "[Epoch 2] Step 3600 | Recon: 0.3229 | Loss: 0.4099 | Perplexity: 152.85\n",
      "[Epoch 2] Step 3650 | Recon: 0.2740 | Loss: 0.3650 | Perplexity: 155.15\n",
      "[Epoch 2] Step 3700 | Recon: 0.3287 | Loss: 0.4411 | Perplexity: 155.81\n",
      "[Epoch 2] Step 3750 | Recon: 0.3286 | Loss: 0.4322 | Perplexity: 152.17\n",
      "[Epoch 2] Step 3800 | Recon: 0.3194 | Loss: 0.4140 | Perplexity: 156.82\n",
      "[Epoch 2] Step 3850 | Recon: 0.3222 | Loss: 0.4187 | Perplexity: 151.99\n",
      "[Epoch 2] Step 3900 | Recon: 0.3068 | Loss: 0.4164 | Perplexity: 155.70\n",
      "[Epoch 2] Step 3950 | Recon: 0.3132 | Loss: 0.4032 | Perplexity: 150.81\n",
      "[Epoch 2] Step 4000 | Recon: 0.2689 | Loss: 0.3559 | Perplexity: 142.90\n",
      "[Epoch 2] Step 4050 | Recon: 0.2582 | Loss: 0.3464 | Perplexity: 143.51\n",
      "[Epoch 2] Step 4100 | Recon: 0.3142 | Loss: 0.4140 | Perplexity: 155.08\n",
      "[Epoch 2] Step 4150 | Recon: 0.3513 | Loss: 0.4800 | Perplexity: 152.56\n",
      "[Epoch 2] Step 4200 | Recon: 0.2554 | Loss: 0.3245 | Perplexity: 148.07\n",
      "[Epoch 2] Step 4250 | Recon: 0.2775 | Loss: 0.3692 | Perplexity: 147.71\n",
      "[Epoch 2] Step 4300 | Recon: 0.2645 | Loss: 0.3530 | Perplexity: 149.87\n",
      "[Epoch 2] Step 4350 | Recon: 0.2903 | Loss: 0.3811 | Perplexity: 140.65\n",
      "[Epoch 2] Step 4400 | Recon: 0.3321 | Loss: 0.4401 | Perplexity: 157.14\n",
      "[Epoch 2] Step 4450 | Recon: 0.3145 | Loss: 0.4136 | Perplexity: 157.53\n",
      "[Epoch 2] Step 4500 | Recon: 0.2824 | Loss: 0.3758 | Perplexity: 156.30\n",
      "[Epoch 2] Step 4550 | Recon: 0.2496 | Loss: 0.3338 | Perplexity: 147.83\n",
      "[Epoch 2] Step 4600 | Recon: 0.2685 | Loss: 0.3652 | Perplexity: 148.32\n",
      "[Epoch 2] Step 4650 | Recon: 0.2909 | Loss: 0.3847 | Perplexity: 159.82\n",
      "[Epoch 2] ⏳ Running CGA update for underutilized tokens...\n",
      "[Epoch 2] ✅ CGA update complete.\n",
      "\n",
      "[Epoch 3] Step 4700 | Recon: 0.2818 | Loss: 0.3619 | Perplexity: 162.08\n",
      "[Epoch 3] Step 4750 | Recon: 0.3248 | Loss: 0.4202 | Perplexity: 154.37\n",
      "[Epoch 3] Step 4800 | Recon: 0.2988 | Loss: 0.4233 | Perplexity: 153.60\n",
      "[Epoch 3] Step 4850 | Recon: 0.2695 | Loss: 0.3585 | Perplexity: 144.09\n",
      "[Epoch 3] Step 4900 | Recon: 0.2711 | Loss: 0.3733 | Perplexity: 148.78\n",
      "[Epoch 3] Step 4950 | Recon: 0.2821 | Loss: 0.3907 | Perplexity: 156.78\n",
      "[Epoch 3] Step 5000 | Recon: 0.3061 | Loss: 0.4081 | Perplexity: 160.76\n",
      "[Epoch 3] Step 5050 | Recon: 0.3146 | Loss: 0.4246 | Perplexity: 158.79\n",
      "[Epoch 3] Step 5100 | Recon: 0.3161 | Loss: 0.4330 | Perplexity: 154.24\n",
      "[Epoch 3] Step 5150 | Recon: 0.2630 | Loss: 0.3606 | Perplexity: 155.84\n",
      "[Epoch 3] Step 5200 | Recon: 0.2613 | Loss: 0.3509 | Perplexity: 156.37\n",
      "[Epoch 3] Step 5250 | Recon: 0.2576 | Loss: 0.3511 | Perplexity: 156.81\n",
      "[Epoch 3] Step 5300 | Recon: 0.3114 | Loss: 0.4146 | Perplexity: 157.28\n",
      "[Epoch 3] Step 5350 | Recon: 0.2889 | Loss: 0.3804 | Perplexity: 161.13\n",
      "[Epoch 3] Step 5400 | Recon: 0.3135 | Loss: 0.4079 | Perplexity: 161.41\n",
      "[Epoch 3] Step 5450 | Recon: 0.2645 | Loss: 0.3563 | Perplexity: 152.51\n",
      "[Epoch 3] Step 5500 | Recon: 0.2770 | Loss: 0.3757 | Perplexity: 158.12\n",
      "[Epoch 3] Step 5550 | Recon: 0.2790 | Loss: 0.3639 | Perplexity: 157.06\n",
      "[Epoch 3] Step 5600 | Recon: 0.2785 | Loss: 0.3774 | Perplexity: 151.55\n",
      "[Epoch 3] Step 5650 | Recon: 0.2957 | Loss: 0.4333 | Perplexity: 158.34\n",
      "[Epoch 3] Step 5700 | Recon: 0.2839 | Loss: 0.3946 | Perplexity: 161.66\n",
      "[Epoch 3] Step 5750 | Recon: 0.3046 | Loss: 0.4017 | Perplexity: 164.44\n",
      "[Epoch 3] Step 5800 | Recon: 0.2596 | Loss: 0.3538 | Perplexity: 155.58\n",
      "[Epoch 3] Step 5850 | Recon: 0.2657 | Loss: 0.3686 | Perplexity: 153.58\n",
      "[Epoch 3] Step 5900 | Recon: 0.2781 | Loss: 0.3782 | Perplexity: 157.34\n",
      "[Epoch 3] Step 5950 | Recon: 0.2738 | Loss: 0.3803 | Perplexity: 161.84\n",
      "[Epoch 3] Step 6000 | Recon: 0.3211 | Loss: 0.4806 | Perplexity: 158.87\n",
      "[Epoch 3] Step 6050 | Recon: 0.2794 | Loss: 0.3840 | Perplexity: 159.87\n",
      "[Epoch 3] Step 6100 | Recon: 0.3464 | Loss: 0.4698 | Perplexity: 169.01\n",
      "[Epoch 3] Step 6150 | Recon: 0.2834 | Loss: 0.3958 | Perplexity: 161.35\n",
      "[Epoch 3] Step 6200 | Recon: 0.2591 | Loss: 0.3631 | Perplexity: 161.09\n",
      "[Epoch 3] Step 6250 | Recon: 0.2408 | Loss: 0.3347 | Perplexity: 154.32\n",
      "[Epoch 3] ⏳ Running CGA update for underutilized tokens...\n",
      "[Epoch 3] ✅ CGA update complete.\n",
      "\n",
      "[Epoch 4] Step 6300 | Recon: 0.3183 | Loss: 0.4462 | Perplexity: 168.33\n",
      "[Epoch 4] Step 6350 | Recon: 0.2549 | Loss: 0.3497 | Perplexity: 158.06\n",
      "[Epoch 4] Step 6400 | Recon: 0.2529 | Loss: 0.3711 | Perplexity: 162.26\n",
      "[Epoch 4] Step 6450 | Recon: 0.2691 | Loss: 0.3834 | Perplexity: 166.11\n",
      "[Epoch 4] Step 6500 | Recon: 0.2827 | Loss: 0.3958 | Perplexity: 164.60\n",
      "[Epoch 4] Step 6550 | Recon: 0.2548 | Loss: 0.3565 | Perplexity: 161.08\n",
      "[Epoch 4] Step 6600 | Recon: 0.3143 | Loss: 0.4348 | Perplexity: 167.74\n",
      "[Epoch 4] Step 6650 | Recon: 0.2616 | Loss: 0.3821 | Perplexity: 159.81\n",
      "[Epoch 4] Step 6700 | Recon: 0.2979 | Loss: 0.4142 | Perplexity: 167.33\n",
      "[Epoch 4] Step 6750 | Recon: 0.2801 | Loss: 0.4418 | Perplexity: 165.98\n",
      "[Epoch 4] Step 6800 | Recon: 0.2604 | Loss: 0.3582 | Perplexity: 168.26\n",
      "[Epoch 4] Step 6850 | Recon: 0.2929 | Loss: 0.4041 | Perplexity: 166.30\n",
      "[Epoch 4] Step 6900 | Recon: 0.2627 | Loss: 0.3605 | Perplexity: 165.22\n",
      "[Epoch 4] Step 6950 | Recon: 0.2877 | Loss: 0.4246 | Perplexity: 168.66\n",
      "[Epoch 4] Step 7000 | Recon: 0.3288 | Loss: 0.5267 | Perplexity: 153.50\n",
      "[Epoch 4] Step 7050 | Recon: 0.2737 | Loss: 0.3907 | Perplexity: 160.95\n",
      "[Epoch 4] Step 7100 | Recon: 0.2478 | Loss: 0.3570 | Perplexity: 149.99\n",
      "[Epoch 4] Step 7150 | Recon: 0.3197 | Loss: 0.4576 | Perplexity: 164.24\n",
      "[Epoch 4] Step 7200 | Recon: 0.2546 | Loss: 0.3597 | Perplexity: 161.22\n",
      "[Epoch 4] Step 7250 | Recon: 0.3129 | Loss: 0.4615 | Perplexity: 162.95\n",
      "[Epoch 4] Step 7300 | Recon: 0.2885 | Loss: 0.4041 | Perplexity: 172.56\n",
      "[Epoch 4] Step 7350 | Recon: 0.2688 | Loss: 0.3829 | Perplexity: 166.03\n",
      "[Epoch 4] Step 7400 | Recon: 0.2508 | Loss: 0.3557 | Perplexity: 166.80\n",
      "[Epoch 4] Step 7450 | Recon: 0.2775 | Loss: 0.4022 | Perplexity: 162.29\n",
      "[Epoch 4] Step 7500 | Recon: 0.2635 | Loss: 0.3791 | Perplexity: 159.63\n",
      "[Epoch 4] Step 7550 | Recon: 0.2644 | Loss: 0.3644 | Perplexity: 166.45\n",
      "[Epoch 4] Step 7600 | Recon: 0.3078 | Loss: 0.4264 | Perplexity: 173.30\n",
      "[Epoch 4] Step 7650 | Recon: 0.2986 | Loss: 0.4257 | Perplexity: 168.12\n",
      "[Epoch 4] Step 7700 | Recon: 0.2517 | Loss: 0.3608 | Perplexity: 168.91\n",
      "[Epoch 4] Step 7750 | Recon: 0.3051 | Loss: 0.4310 | Perplexity: 167.34\n",
      "[Epoch 4] Step 7800 | Recon: 0.2983 | Loss: 0.4263 | Perplexity: 172.69\n",
      "[Epoch 4] ⏳ Running CGA update for underutilized tokens...\n",
      "[Epoch 4] ✅ CGA update complete.\n",
      "\n",
      "[Epoch 5] Step 7850 | Recon: 0.3247 | Loss: 0.4720 | Perplexity: 176.67\n",
      "[Epoch 5] Step 7900 | Recon: 0.2851 | Loss: 0.4103 | Perplexity: 169.42\n",
      "[Epoch 5] Step 7950 | Recon: 0.2868 | Loss: 0.4191 | Perplexity: 163.30\n",
      "[Epoch 5] Step 8000 | Recon: 0.2641 | Loss: 0.3773 | Perplexity: 160.45\n",
      "[Epoch 5] Step 8050 | Recon: 0.3018 | Loss: 0.4267 | Perplexity: 170.50\n",
      "[Epoch 5] Step 8100 | Recon: 0.2719 | Loss: 0.3948 | Perplexity: 165.04\n",
      "[Epoch 5] Step 8150 | Recon: 0.2753 | Loss: 0.3982 | Perplexity: 171.69\n",
      "[Epoch 5] Step 8200 | Recon: 0.2635 | Loss: 0.3807 | Perplexity: 167.19\n",
      "[Epoch 5] Step 8250 | Recon: 0.2803 | Loss: 0.4043 | Perplexity: 164.24\n",
      "[Epoch 5] Step 8300 | Recon: 0.2626 | Loss: 0.3851 | Perplexity: 170.02\n",
      "[Epoch 5] Step 8350 | Recon: 0.2455 | Loss: 0.3619 | Perplexity: 162.08\n",
      "[Epoch 5] Step 8400 | Recon: 0.3025 | Loss: 0.4414 | Perplexity: 173.41\n",
      "[Epoch 5] Step 8450 | Recon: 0.2890 | Loss: 0.4107 | Perplexity: 170.25\n",
      "[Epoch 5] Step 8500 | Recon: 0.2816 | Loss: 0.4078 | Perplexity: 168.64\n",
      "[Epoch 5] Step 8550 | Recon: 0.2758 | Loss: 0.3852 | Perplexity: 166.52\n",
      "[Epoch 5] Step 8600 | Recon: 0.2708 | Loss: 0.3834 | Perplexity: 174.21\n",
      "[Epoch 5] Step 8650 | Recon: 0.2979 | Loss: 0.4301 | Perplexity: 176.85\n",
      "[Epoch 5] Step 8700 | Recon: 0.2498 | Loss: 0.3692 | Perplexity: 163.76\n",
      "[Epoch 5] Step 8750 | Recon: 0.2417 | Loss: 0.3579 | Perplexity: 161.91\n",
      "[Epoch 5] Step 8800 | Recon: 0.3334 | Loss: 0.4865 | Perplexity: 165.36\n",
      "[Epoch 5] Step 8850 | Recon: 0.2917 | Loss: 0.4229 | Perplexity: 175.29\n",
      "[Epoch 5] Step 8900 | Recon: 0.2324 | Loss: 0.3445 | Perplexity: 158.25\n",
      "[Epoch 5] Step 8950 | Recon: 0.2362 | Loss: 0.3492 | Perplexity: 168.79\n",
      "[Epoch 5] Step 9000 | Recon: 0.2830 | Loss: 0.4074 | Perplexity: 173.26\n",
      "[Epoch 5] Step 9050 | Recon: 0.2478 | Loss: 0.3610 | Perplexity: 164.64\n",
      "[Epoch 5] Step 9100 | Recon: 0.3000 | Loss: 0.4411 | Perplexity: 172.61\n",
      "[Epoch 5] Step 9150 | Recon: 0.2766 | Loss: 0.4131 | Perplexity: 172.65\n",
      "[Epoch 5] Step 9200 | Recon: 0.2684 | Loss: 0.3825 | Perplexity: 173.19\n",
      "[Epoch 5] Step 9250 | Recon: 0.2257 | Loss: 0.3286 | Perplexity: 163.50\n",
      "[Epoch 5] Step 9300 | Recon: 0.2489 | Loss: 0.3619 | Perplexity: 167.68\n",
      "[Epoch 5] Step 9350 | Recon: 0.3118 | Loss: 0.4546 | Perplexity: 176.89\n",
      "[Epoch 5] ⏳ Running CGA update for underutilized tokens...\n",
      "[Epoch 5] ✅ CGA update complete.\n",
      "\n",
      "[Epoch 6] Step 9400 | Recon: 0.2654 | Loss: 0.3937 | Perplexity: 165.07\n",
      "[Epoch 6] Step 9450 | Recon: 0.2738 | Loss: 0.4022 | Perplexity: 164.35\n",
      "[Epoch 6] Step 9500 | Recon: 0.3002 | Loss: 0.4257 | Perplexity: 169.62\n",
      "[Epoch 6] Step 9550 | Recon: 0.2912 | Loss: 0.4212 | Perplexity: 183.15\n",
      "[Epoch 6] Step 9600 | Recon: 0.2632 | Loss: 0.3959 | Perplexity: 168.58\n",
      "[Epoch 6] Step 9650 | Recon: 0.2351 | Loss: 0.3447 | Perplexity: 167.75\n",
      "[Epoch 6] Step 9700 | Recon: 0.2366 | Loss: 0.3629 | Perplexity: 170.73\n",
      "[Epoch 6] Step 9750 | Recon: 0.2613 | Loss: 0.3954 | Perplexity: 169.11\n",
      "[Epoch 6] Step 9800 | Recon: 0.2804 | Loss: 0.4107 | Perplexity: 166.27\n",
      "[Epoch 6] Step 9850 | Recon: 0.2885 | Loss: 0.4177 | Perplexity: 166.77\n",
      "[Epoch 6] Step 9900 | Recon: 0.3103 | Loss: 0.4460 | Perplexity: 163.64\n",
      "[Epoch 6] Step 9950 | Recon: 0.2255 | Loss: 0.3346 | Perplexity: 166.87\n",
      "[Epoch 6] Step 10000 | Recon: 0.2610 | Loss: 0.3812 | Perplexity: 171.66\n",
      "[Epoch 6] Step 10050 | Recon: 0.2660 | Loss: 0.3828 | Perplexity: 170.77\n",
      "[Epoch 6] Step 10100 | Recon: 0.2567 | Loss: 0.3705 | Perplexity: 173.23\n",
      "[Epoch 6] Step 10150 | Recon: 0.2905 | Loss: 0.4277 | Perplexity: 169.57\n",
      "[Epoch 6] Step 10200 | Recon: 0.2532 | Loss: 0.3805 | Perplexity: 160.40\n",
      "[Epoch 6] Step 10250 | Recon: 0.2252 | Loss: 0.3231 | Perplexity: 148.95\n",
      "[Epoch 6] Step 10300 | Recon: 0.2429 | Loss: 0.3533 | Perplexity: 169.39\n",
      "[Epoch 6] Step 10350 | Recon: 0.2835 | Loss: 0.4184 | Perplexity: 165.10\n",
      "[Epoch 6] Step 10400 | Recon: 0.3069 | Loss: 0.4532 | Perplexity: 167.87\n",
      "[Epoch 6] Step 10450 | Recon: 0.2508 | Loss: 0.3708 | Perplexity: 161.80\n",
      "[Epoch 6] Step 10500 | Recon: 0.2433 | Loss: 0.3710 | Perplexity: 162.70\n",
      "[Epoch 6] Step 10550 | Recon: 0.2730 | Loss: 0.3999 | Perplexity: 167.48\n",
      "[Epoch 6] Step 10600 | Recon: 0.3022 | Loss: 0.4377 | Perplexity: 166.88\n",
      "[Epoch 6] Step 10650 | Recon: 0.2508 | Loss: 0.3706 | Perplexity: 167.67\n",
      "[Epoch 6] Step 10700 | Recon: 0.2663 | Loss: 0.4048 | Perplexity: 159.02\n",
      "[Epoch 6] Step 10750 | Recon: 0.2906 | Loss: 0.4534 | Perplexity: 173.86\n",
      "[Epoch 6] Step 10800 | Recon: 0.2306 | Loss: 0.3466 | Perplexity: 158.17\n",
      "[Epoch 6] Step 10850 | Recon: 0.2405 | Loss: 0.3525 | Perplexity: 165.17\n",
      "[Epoch 6] Step 10900 | Recon: 0.2761 | Loss: 0.4093 | Perplexity: 167.68\n",
      "[Epoch 6] ⏳ Running CGA update for underutilized tokens...\n",
      "[Epoch 6] ✅ CGA update complete.\n",
      "\n",
      "[Epoch 7] Step 10950 | Recon: 0.2776 | Loss: 0.4185 | Perplexity: 171.95\n",
      "[Epoch 7] Step 11000 | Recon: 0.2648 | Loss: 0.3852 | Perplexity: 169.71\n",
      "[Epoch 7] Step 11050 | Recon: 0.2747 | Loss: 0.3994 | Perplexity: 171.67\n",
      "[Epoch 7] Step 11100 | Recon: 0.2710 | Loss: 0.3940 | Perplexity: 167.00\n",
      "[Epoch 7] Step 11150 | Recon: 0.2312 | Loss: 0.3537 | Perplexity: 156.99\n",
      "[Epoch 7] Step 11200 | Recon: 0.2589 | Loss: 0.3827 | Perplexity: 164.20\n",
      "[Epoch 7] Step 11250 | Recon: 0.2537 | Loss: 0.3775 | Perplexity: 164.34\n",
      "[Epoch 7] Step 11300 | Recon: 0.2761 | Loss: 0.4078 | Perplexity: 169.86\n",
      "[Epoch 7] Step 11350 | Recon: 0.2744 | Loss: 0.4147 | Perplexity: 160.65\n",
      "[Epoch 7] Step 11400 | Recon: 0.2406 | Loss: 0.3569 | Perplexity: 160.54\n",
      "[Epoch 7] Step 11450 | Recon: 0.2790 | Loss: 0.4151 | Perplexity: 169.15\n",
      "[Epoch 7] Step 11500 | Recon: 0.2728 | Loss: 0.4173 | Perplexity: 169.95\n",
      "[Epoch 7] Step 11550 | Recon: 0.2577 | Loss: 0.3863 | Perplexity: 168.24\n",
      "[Epoch 7] Step 11600 | Recon: 0.3007 | Loss: 0.4474 | Perplexity: 167.49\n",
      "[Epoch 7] Step 11650 | Recon: 0.3211 | Loss: 0.4733 | Perplexity: 168.88\n",
      "[Epoch 7] Step 11700 | Recon: 0.2839 | Loss: 0.4316 | Perplexity: 167.52\n",
      "[Epoch 7] Step 11750 | Recon: 0.2343 | Loss: 0.3644 | Perplexity: 161.71\n",
      "[Epoch 7] Step 11800 | Recon: 0.2727 | Loss: 0.4154 | Perplexity: 172.11\n",
      "[Epoch 7] Step 11850 | Recon: 0.2533 | Loss: 0.3788 | Perplexity: 164.46\n",
      "[Epoch 7] Step 11900 | Recon: 0.2682 | Loss: 0.3932 | Perplexity: 163.98\n",
      "[Epoch 7] Step 11950 | Recon: 0.2603 | Loss: 0.3760 | Perplexity: 162.97\n",
      "[Epoch 7] Step 12000 | Recon: 0.2771 | Loss: 0.4269 | Perplexity: 175.33\n",
      "[Epoch 7] Step 12050 | Recon: 0.2321 | Loss: 0.3471 | Perplexity: 164.43\n",
      "[Epoch 7] Step 12100 | Recon: 0.2654 | Loss: 0.3928 | Perplexity: 171.95\n",
      "[Epoch 7] Step 12150 | Recon: 0.2668 | Loss: 0.4018 | Perplexity: 163.78\n",
      "[Epoch 7] Step 12200 | Recon: 0.2807 | Loss: 0.4137 | Perplexity: 169.97\n",
      "[Epoch 7] Step 12250 | Recon: 0.2510 | Loss: 0.3791 | Perplexity: 166.15\n",
      "[Epoch 7] Step 12300 | Recon: 0.2538 | Loss: 0.3826 | Perplexity: 164.13\n",
      "[Epoch 7] Step 12350 | Recon: 0.2554 | Loss: 0.3746 | Perplexity: 169.87\n",
      "[Epoch 7] Step 12400 | Recon: 0.2914 | Loss: 0.4361 | Perplexity: 175.22\n",
      "[Epoch 7] Step 12450 | Recon: 0.3223 | Loss: 0.4854 | Perplexity: 180.17\n",
      "[Epoch 7] Step 12500 | Recon: 0.2724 | Loss: 0.4104 | Perplexity: 169.67\n",
      "[Epoch 7] ⏳ Running CGA update for underutilized tokens...\n",
      "[Epoch 7] ✅ CGA update complete.\n",
      "\n",
      "[Epoch 8] Step 12550 | Recon: 0.2750 | Loss: 0.4167 | Perplexity: 169.71\n",
      "[Epoch 8] Step 12600 | Recon: 0.2637 | Loss: 0.3885 | Perplexity: 170.45\n",
      "[Epoch 8] Step 12650 | Recon: 0.2430 | Loss: 0.3729 | Perplexity: 154.27\n",
      "[Epoch 8] Step 12700 | Recon: 0.2819 | Loss: 0.4163 | Perplexity: 170.29\n",
      "[Epoch 8] Step 12750 | Recon: 0.2480 | Loss: 0.3747 | Perplexity: 161.19\n",
      "[Epoch 8] Step 12800 | Recon: 0.2896 | Loss: 0.4316 | Perplexity: 167.08\n",
      "[Epoch 8] Step 12850 | Recon: 0.3175 | Loss: 0.4699 | Perplexity: 168.82\n",
      "[Epoch 8] Step 12900 | Recon: 0.2339 | Loss: 0.3617 | Perplexity: 160.54\n",
      "[Epoch 8] Step 12950 | Recon: 0.2706 | Loss: 0.4187 | Perplexity: 168.91\n",
      "[Epoch 8] Step 13000 | Recon: 0.2815 | Loss: 0.4264 | Perplexity: 167.46\n",
      "[Epoch 8] Step 13050 | Recon: 0.2569 | Loss: 0.3840 | Perplexity: 162.77\n",
      "[Epoch 8] Step 13100 | Recon: 0.2616 | Loss: 0.3990 | Perplexity: 166.63\n",
      "[Epoch 8] Step 13150 | Recon: 0.2671 | Loss: 0.4018 | Perplexity: 167.44\n",
      "[Epoch 8] Step 13200 | Recon: 0.3173 | Loss: 0.4863 | Perplexity: 179.15\n",
      "[Epoch 8] Step 13250 | Recon: 0.2678 | Loss: 0.4092 | Perplexity: 166.68\n",
      "[Epoch 8] Step 13300 | Recon: 0.2446 | Loss: 0.3743 | Perplexity: 161.83\n",
      "[Epoch 8] Step 13350 | Recon: 0.2703 | Loss: 0.3945 | Perplexity: 174.48\n",
      "[Epoch 8] Step 13400 | Recon: 0.2690 | Loss: 0.4139 | Perplexity: 164.43\n",
      "[Epoch 8] Step 13450 | Recon: 0.2866 | Loss: 0.4282 | Perplexity: 175.92\n",
      "[Epoch 8] Step 13500 | Recon: 0.2399 | Loss: 0.3704 | Perplexity: 164.88\n",
      "[Epoch 8] Step 13550 | Recon: 0.2845 | Loss: 0.4169 | Perplexity: 172.56\n",
      "[Epoch 8] Step 13600 | Recon: 0.2723 | Loss: 0.4018 | Perplexity: 167.91\n",
      "[Epoch 8] Step 13650 | Recon: 0.2597 | Loss: 0.3951 | Perplexity: 170.64\n",
      "[Epoch 8] Step 13700 | Recon: 0.2650 | Loss: 0.3983 | Perplexity: 176.82\n",
      "[Epoch 8] Step 13750 | Recon: 0.2744 | Loss: 0.4140 | Perplexity: 166.47\n",
      "[Epoch 8] Step 13800 | Recon: 0.2715 | Loss: 0.3974 | Perplexity: 163.46\n",
      "[Epoch 8] Step 13850 | Recon: 0.2606 | Loss: 0.4070 | Perplexity: 174.09\n",
      "[Epoch 8] Step 13900 | Recon: 0.3063 | Loss: 0.4529 | Perplexity: 177.88\n",
      "[Epoch 8] Step 13950 | Recon: 0.2591 | Loss: 0.3945 | Perplexity: 168.45\n",
      "[Epoch 8] Step 14000 | Recon: 0.2753 | Loss: 0.4303 | Perplexity: 163.38\n",
      "[Epoch 8] Step 14050 | Recon: 0.2841 | Loss: 0.4224 | Perplexity: 173.21\n",
      "[Epoch 8] ⏳ Running CGA update for underutilized tokens...\n",
      "[Epoch 8] ✅ CGA update complete.\n",
      "\n",
      "[Epoch 9] Step 14100 | Recon: 0.2381 | Loss: 0.3648 | Perplexity: 163.28\n",
      "[Epoch 9] Step 14150 | Recon: 0.2471 | Loss: 0.3879 | Perplexity: 165.47\n",
      "[Epoch 9] Step 14200 | Recon: 0.2379 | Loss: 0.3576 | Perplexity: 156.67\n",
      "[Epoch 9] Step 14250 | Recon: 0.2929 | Loss: 0.4276 | Perplexity: 159.23\n",
      "[Epoch 9] Step 14300 | Recon: 0.2595 | Loss: 0.4036 | Perplexity: 167.75\n",
      "[Epoch 9] Step 14350 | Recon: 0.2449 | Loss: 0.3689 | Perplexity: 161.69\n",
      "[Epoch 9] Step 14400 | Recon: 0.2494 | Loss: 0.3755 | Perplexity: 164.31\n",
      "[Epoch 9] Step 14450 | Recon: 0.2870 | Loss: 0.4381 | Perplexity: 171.23\n",
      "[Epoch 9] Step 14500 | Recon: 0.2674 | Loss: 0.4084 | Perplexity: 166.14\n",
      "[Epoch 9] Step 14550 | Recon: 0.2767 | Loss: 0.4258 | Perplexity: 172.39\n",
      "[Epoch 9] Step 14600 | Recon: 0.2656 | Loss: 0.4151 | Perplexity: 171.36\n",
      "[Epoch 9] Step 14650 | Recon: 0.2629 | Loss: 0.4052 | Perplexity: 171.50\n",
      "[Epoch 9] Step 14700 | Recon: 0.2569 | Loss: 0.3957 | Perplexity: 159.59\n",
      "[Epoch 9] Step 14750 | Recon: 0.2891 | Loss: 0.4297 | Perplexity: 167.13\n",
      "[Epoch 9] Step 14800 | Recon: 0.3029 | Loss: 0.4556 | Perplexity: 174.95\n",
      "[Epoch 9] Step 14850 | Recon: 0.2608 | Loss: 0.4012 | Perplexity: 159.43\n",
      "[Epoch 9] Step 14900 | Recon: 0.2425 | Loss: 0.3890 | Perplexity: 163.91\n",
      "[Epoch 9] Step 14950 | Recon: 0.2375 | Loss: 0.3681 | Perplexity: 162.73\n",
      "[Epoch 9] Step 15000 | Recon: 0.2749 | Loss: 0.4110 | Perplexity: 166.69\n",
      "[Epoch 9] Step 15050 | Recon: 0.2809 | Loss: 0.4209 | Perplexity: 167.15\n",
      "[Epoch 9] Step 15100 | Recon: 0.2629 | Loss: 0.4131 | Perplexity: 163.26\n",
      "[Epoch 9] Step 15150 | Recon: 0.2678 | Loss: 0.4084 | Perplexity: 168.46\n",
      "[Epoch 9] Step 15200 | Recon: 0.2723 | Loss: 0.4218 | Perplexity: 166.74\n",
      "[Epoch 9] Step 15250 | Recon: 0.2443 | Loss: 0.3791 | Perplexity: 159.00\n",
      "[Epoch 9] Step 15300 | Recon: 0.2730 | Loss: 0.4157 | Perplexity: 156.08\n",
      "[Epoch 9] Step 15350 | Recon: 0.2594 | Loss: 0.4298 | Perplexity: 160.36\n",
      "[Epoch 9] Step 15400 | Recon: 0.2663 | Loss: 0.4106 | Perplexity: 163.69\n",
      "[Epoch 9] Step 15450 | Recon: 0.2612 | Loss: 0.4004 | Perplexity: 164.66\n",
      "[Epoch 9] Step 15500 | Recon: 0.2619 | Loss: 0.3952 | Perplexity: 163.59\n",
      "[Epoch 9] Step 15550 | Recon: 0.2391 | Loss: 0.3663 | Perplexity: 167.17\n",
      "[Epoch 9] Step 15600 | Recon: 0.2681 | Loss: 0.4059 | Perplexity: 168.46\n",
      "[Epoch 9] ⏳ Running CGA update for underutilized tokens...\n",
      "[Epoch 9] ✅ CGA update complete.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import argparse\n",
    "import utils\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "\"\"\"\n",
    "Hyperparameters\n",
    "\"\"\"\n",
    "timestamp = utils.readable_timestamp()\n",
    "\n",
    "parser.add_argument(\"--batch_size\", type=int, default=32)\n",
    "parser.add_argument(\"--n_updates\", type=int, default=10)\n",
    "parser.add_argument(\"--n_hiddens\", type=int, default=128)\n",
    "parser.add_argument(\"--n_residual_hiddens\", type=int, default=32)\n",
    "parser.add_argument(\"--n_residual_layers\", type=int, default=2)\n",
    "parser.add_argument(\"--embedding_dim\", type=int, default=64)\n",
    "parser.add_argument(\"--n_embeddings\", type=int, default=512)\n",
    "parser.add_argument(\"--beta\", type=float, default=.25)\n",
    "parser.add_argument(\"--learning_rate\", type=float, default=3e-4)\n",
    "parser.add_argument(\"--log_interval\", type=int, default=50)\n",
    "parser.add_argument(\"--dataset\",  type=str, default='CIFAR10')\n",
    "\n",
    "# whether or not to save model\n",
    "parser.add_argument(\"-save\", action=\"store_true\")\n",
    "parser.add_argument(\"--filename\",  type=str, default=timestamp)\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "args.save = True\n",
    "if args.save:\n",
    "    print('Results will be saved in ./results/vqvae_' + args.filename + '.pth')\n",
    "\n",
    "\n",
    "training_data, validation_data, training_loader, validation_loader, x_train_var = utils.load_data_and_data_loaders(\n",
    "    args.dataset, args.batch_size)\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.learning_rate, amsgrad=True)\n",
    "\n",
    "\n",
    "results = {\n",
    "    'n_updates': 0,\n",
    "    'recon_errors': [],\n",
    "    'loss_vals': [],\n",
    "    'perplexities': [],\n",
    "}\n",
    "def train():\n",
    "    model.train()\n",
    "    step = 0\n",
    "\n",
    "    for epoch in range(args.n_updates):\n",
    "        all_z_e = []\n",
    "        all_ei = []\n",
    "        all_ej = []\n",
    "\n",
    "        for (x, _) in training_loader:\n",
    "            x = x.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass with z_e, top-1, top-2 indices\n",
    "            embedding_loss, x_hat, perplexity, z_e, ei, ej = model(x)\n",
    "            recon_loss = torch.mean((x_hat - x) ** 2) / x_train_var\n",
    "            loss = recon_loss + embedding_loss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # 기록\n",
    "            results[\"recon_errors\"].append(recon_loss.item())\n",
    "            results[\"perplexities\"].append(perplexity.item())\n",
    "            results[\"loss_vals\"].append(loss.item())\n",
    "            results[\"n_updates\"] = step\n",
    "\n",
    "            # CGA 준비를 위한 데이터 누적\n",
    "            z_e_flat = z_e.permute(0, 2, 3, 1).reshape(-1, z_e.shape[1])  # (BHW, D)\n",
    "            all_z_e.append(z_e_flat.detach().cpu())\n",
    "            all_ei.append(ei.view(-1).detach().cpu())\n",
    "            all_ej.append(ej.view(-1).detach().cpu())\n",
    "\n",
    "            # 로그\n",
    "            if step % args.log_interval == 0:\n",
    "                print(f\"[Epoch {epoch}] Step {step} | Recon: {recon_loss.item():.4f} | \"\n",
    "                      f\"Loss: {loss.item():.4f} | Perplexity: {perplexity.item():.2f}\")\n",
    "\n",
    "            step += 1\n",
    "\n",
    "        # === ✅ 1 에폭 끝난 후 CGA 업데이트 ===\n",
    "        print(f\"[Epoch {epoch}] ⏳ Running CGA update for underutilized tokens...\")\n",
    "        z_e_all = torch.cat(all_z_e, dim=0).to(device)\n",
    "        ei_all = torch.cat(all_ei, dim=0)\n",
    "        ej_all = torch.cat(all_ej, dim=0)\n",
    "\n",
    "        usage_counts = torch.bincount(ei_all, minlength=model.vector_quantization.n_e)\n",
    "        update_codebook_with_cga(model, z_e_all, ei_all, ej_all, usage_counts)\n",
    "\n",
    "        print(f\"[Epoch {epoch}] ✅ CGA update complete.\\n\")\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vqvae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
